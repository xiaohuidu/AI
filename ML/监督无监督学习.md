原文链接：https://blog.csdn.net/chumingqian/article/details/131315745

本文探讨了监督学习、半监督学习、弱监督学习和自监督学习的概念。监督学习依赖于带标签的数据，而半监督学习利用少量标签数据和大量未标记数据进行训练。自监督学习通过数据的内在结构创建人工标签，无监督学习则寻找数据中的模式和结构，如聚类。各种学习方法各有优缺点，适用于不同场景和任务

## 1. 有监督

[有监督学习](https://so.csdn.net/so/search?q=%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0&spm=1001.2101.3001.7020)的特点，是数据集通常带有人工标签的数据集。

![enter image description here](https://github.com/xiaohuidu/AI/blob/master/images/196.png)


**1.1 定义**

监督学习提供了一组输入输出对，这样我们就可以学习一个将输入映射到正确输出的中间系统。

监督学习的一个简单示例是根据图像数据集及其相应类别（我们将其称为标签）确定图像的类别（即，狗/猫等）。

对于给定的输入标签对，当前流行的方法是直接训练深度神经网络（即卷积神经网络）以从给定图像输出标签预测，计算预测与实际正确值之间的可微损失答案，并通过网络反向传播来更新权重以优化预测。

总的来说，监督学习是最直接的学习方法，因为它假设给定每个图像的标签，这简化了学习过程，因为网络更容易学习。

有监督学习的局限性，数据的标注过程是昂贵的。
虽然监督学习假设要训练任务的整个数据集对于每个输入都有相应的标签，但现实可能并不总是这样。

标记是一项劳动密集型处理任务，输入数据通常是不成对的。

1.2　半监督学习
半监督学习旨在解决这个问题：我们如何使用一小组输入输出对和另一组仅输入来优化我们正在解决的任务的模型？

回顾图像分类任务，图像和图像标签现在仅部分存在于数据集中。是否可以在没有任何标签的情况下继续使用数据？

简短的回答是，是的。事实上，有一个称为伪标签的简单技巧可以做到这一点。首先，我们使用具有正确标签的图像来训练分类模型。然后我们使用这个分类模型来标记未标记的图像。然后将带有来自模型的高置信度标签的图像添加到模型中，并将其预测标签作为伪标签用于继续训练。我们迭代这个过程，直到所有数据都被用于最佳分类模型。
————————————————

                            版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。
                        
原文链接：https://blog.csdn.net/chumingqian/article/details/131315745
<!--stackedit_data:
eyJoaXN0b3J5IjpbNzUzMDU0MzEyXX0=
-->