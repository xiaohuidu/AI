原文链接：https://blog.csdn.net/chumingqian/article/details/131315745

本文探讨了监督学习、半监督学习、弱监督学习和自监督学习的概念。监督学习依赖于带标签的数据，而半监督学习利用少量标签数据和大量未标记数据进行训练。自监督学习通过数据的内在结构创建人工标签，无监督学习则寻找数据中的模式和结构，如聚类。各种学习方法各有优缺点，适用于不同场景和任务

## 1. 有监督

[有监督学习](https://so.csdn.net/so/search?q=%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0&spm=1001.2101.3001.7020)的特点，是数据集通常带有人工标签的数据集。

![enter image description here](https://github.com/xiaohuidu/AI/blob/master/images/196.png)


**1.1 定义**

监督学习提供了一组输入输出对，这样我们就可以学习一个将输入映射到正确输出的中间系统。

监督学习的一个简单示例是根据图像数据集及其相应类别（我们将其称为标签）确定图像的类别（即，狗/猫等）。

对于给定的输入标签对，当前流行的方法是直接训练深度神经网络（即卷积神经网络）以从给定图像输出标签预测，计算预测与实际正确值之间的可微损失答案，并通过网络反向传播来更新权重以优化预测。

总的来说，监督学习是最直接的学习方法，因为它假设给定每个图像的标签，这简化了学习过程，因为网络更容易学习。

有监督学习的局限性，数据的标注过程是昂贵的。
虽然监督学习假设要训练任务的整个数据集对于每个输入都有相应的标签，但现实可能并不总是这样。

标记是一项劳动密集型处理任务，输入数据通常是不成对的。

1.2　半监督学习

半监督学习旨在解决这个问题：我们如何使用一小组输入输出对和另一组仅输入来优化我们正在解决的任务的模型？

回顾图像分类任务，图像和图像标签现在仅部分存在于数据集中。是否可以在没有任何标签的情况下继续使用数据？

简短的回答是，是的。事实上，有一个称为伪标签的简单技巧可以做到这一点。首先，我们使用具有正确标签的图像来训练分类模型。然后我们使用这个分类模型来标记未标记的图像。然后将带有来自模型的高置信度标签的图像添加到模型中，并将其预测标签作为伪标签用于继续训练。我们迭代这个过程，直到所有数据都被用于最佳分类模型。

![enter image description here](https://github.com/xiaohuidu/AI/blob/master/images/197.png)

**半监督学习的局限性**：当然，这种方法虽然看似聪明，但很容易出错。如果标记数据的数量非常有限，则模型很可能对训练数据过度拟合，并在早期给出错误的伪标签，导致整个模型完全错误。因此，确定将输入伪标签对纳入训练的置信度阈值也非常重要。

为了避免模型在早期阶段过度拟合，还可以采用数据增强技术来增加训练规模并创建更广泛的数据分布。如果有兴趣，您还可以参考我关于混合作为图像分类任务最主要的增强策略之一的文章。

半监督和弱监督，都属于有监督的类型；
半监督或弱监督混淆：（半监督和弱监督）指的是在数据集中部分一些例子X没有标签，但是数据的人工标签是存在的。

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE5OTAwNjE4ODhdfQ==
-->