## 什么是大语言模型（LLM）

通过海量文本训练的、能识别人类语言、执行语言类任务、拥有大量参数的模型，称之为大语言模型。GPT、LLaMA、Mistral、BERT等都是LLM，LLM是对训练文本信息的压缩，同时拥有了泛化能力，不同于数据库和搜索引擎，LLM能创造性地生成历史上没有出现过的文本内容。

## LLM能做什么

总体可以概括为：创作内容、处理和分析数据、自动化任务、智能客服

• 写作：写邮件、计划书、宣传文案、简单的故事等，可以模仿小红书风格、指定作家风格，尤其适合写长篇套话，但目前要写出完整且有趣的小说还比较难。

• 润色：提供大纲或已有文本，由LLM来扩写、改写，适用于洗稿、避免被查重等场景。

• 总结：提供会议记录、文章，由LLM自动总结要点和待办。

• 翻译：多语言翻译、白话文和文言文翻译，结合特定prompt进行多轮翻译可以实现惊艳的结果。

• 数据分析：从报告中提取数据、分析数据，做成可视化图表。

• 编程：Github Copilot，程序员都应该用。

• 提取结构化信息：从用户的自然语言中，提取出结构化的信息，方便传给程序做自动化处理。

• 智能助手：利用Agent实现工作流

• 智能客服：基于RAG实现智能客服

## LLM有什么缺陷

目前LLM最大的缺陷是幻觉严重，经常会生成无中生有的回复，如果你没有对应的专业知识，很容易被带偏。所以如果你要用于工作、教育等严肃场景，人工二次校验是必要的。幻觉短期内是无法消除的，甚至LLM的泛化能力也跟幻觉有关，就像人类会做离奇的梦一样。为了解决LLM回复准确性的问题，RAG技术被广泛应用。

另外还有一些问题：训练信息更新不及时、逻辑能力差、推理速度慢等。

LLM教程
对于大多数人来说，没必要专门学习LLM的知识，最多学一下Prompt Engineering就够了。就像我们不需要学习iOS和安卓的底层系统，只需要知道有哪些便捷的系统功能即可。


================================

**优秀的LLM教程**

· 3Blue1Brown视频教程

首推这套教程，可视化讲解了Token、Embedding、Transformer等一系列概念，绝对是入门的最佳教程。

深度学习第5章：https://b23.tv/k68hwjD

深度学习第6章：https://b23.tv/11SNpcT

· Cohere文字教程

虽然是英文文字教程，但是写的非常浅显易懂，四级水平就能看懂。

链接：Cohere教程

· 电子书：《大语言模型》

这是一套包含了项目落地和实操的教程，适合程序员和AI从业人员。

链接：Github

· 台大李宏毅课程

大学的实际教学内容，从线性代数的角度讲解Transformer的原理。

视频地址：https://b23.tv/sasg96g

提示词工程（Prompt Engineering）
最有效的提示词策略是：使用更好的模型。使用小模型时各种提示词方法都控制不了输出结果，换成更大更好的模型后，一句提示词就可以解决。

提示词工程是用于弥补现阶段LLM能力的不足，随着LLM的能力提升，提示词工程的作用会越来越小。

这类教程有很多，我常用的是这个：Prompt教程

微调（Finetune）
微调可以补充和强化LLM的知识，例如使用中文数据集微调LLaMA 3 8B，即可大幅提升中文能力、减少回复里出现表情的情况。小模型推荐基于Phi 3、LLaMA 3、Mistral模型微调。中模型推荐基于Yi-34B微调。

这个Github仓库，提供了colab链接，可以在线微调小模型：colab免费微调模型

数据集
数据集的质量对LLM能力有很大的影响，人类可用的数据集现在已经被全部用于训练LLM了，并且已经开始使用AI合成的数据来训练LLM。关于数据集，可以查看这篇数据集综述

对应的开源数据集，包含444个数据集，大小超过774TB，覆盖8种语言：开源数据集

多模态LLM
LLM是语言模型，只能理解文字、生成文字，多模态的含义是除了文字能力外，还可以理解和生成图片、语音、视频。目前多模态LLM有两种，一种是GPT-4V和LLaVA，通过额外的图片识别模块具备多模态能力，另外一种是GPT-4o和Gemini，模型原生就是多模态，可以更快地处理和生成多模态信息。

关于多模态模型的综述

对应的项目地址

RAG
RAG(Retrieval Augmented Generation，检索增强生成)是目前LLM应用落地的重要方向，主要的应用场景是企业客服系统和搜索结果结构化展示（代表作是Perplexity和秘塔）。RAG对数据的规范程度要求比较高，数据越规范，查询效果越好，结合树形结构或知识图谱结构的数据，RAG可以实现更好的效果。

开源RAG框架推荐：Cohere；Cognita

Agent
Agent翻译成中文是智能体的意思，是AGI的前奏。现阶段的Agent只能算工作流，什么时候Agent能根据用户要求直接创建好Agent，才算是真正的智能体。

目前好用的Agent平台是Coze和Dify

LLM越狱
LLM有安全机制，会拒绝回答一些问题，LLM越狱可以让LLM按要求回答任何问题。

这个仓库收集了各个模型的越狱提示词：LLM越狱

本地部署LLM工具
个人电脑运行LLM，最大只能运行20B以下的模型，33B模型需要32G显存。比较适合本地运行的是Phi 3 Medium（14B）、LLaMA 3 8B、Mistral 7B。

推荐以下两个客户端：Ollama； LM Studio

LLM的未来
目前可以预见的趋势：

• Scaling Law 依旧有效，GPT-4 在22年年中完成训练，GPT-5在24年年中完成训练，参数规模提升依旧可以提升性能；

• 原生多模态展露头角，GPT-4o 的亮相，实现了实时语音交互，为语音助手的落地提供了技术支撑；

• 多 token 预测，Meta 发布的多 token 预测方法，一次预测多个 token 而不是单个 token ，可以提升 LLM 的逻辑能力，很有发展前景。

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTIwMjcyNTI5MDUsMTU4MjAzODA0NiwtMT
kwOTExMTUzNl19
-->